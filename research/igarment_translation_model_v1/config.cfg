[paths]
train = null
dev = null
vectors = null
init_tok2vec = null

[system]
seed = 0
gpu_allocator = null

[nlp]
lang = "ja"
pipeline = ["sentencizer","translation_component","garment_lemmatizer","entity_ruler"]
disabled = []
before_creation = null
after_creation = null
after_pipeline_creation = null
batch_size = 1000
vectors = {"@vectors":"spacy.Vectors.v1"}

[nlp.tokenizer]
@tokenizers = "spacy.ja.JapaneseTokenizer"
split_mode = null

[components]

[components.entity_ruler]
factory = "entity_ruler"
ent_id_sep = "||"
matcher_fuzzy_compare = {"@misc":"spacy.levenshtein_compare.v1"}
overwrite_ents = false
phrase_matcher_attr = null
scorer = {"@scorers":"spacy.entity_ruler_scorer.v1"}
validate = false

[components.garment_lemmatizer]
factory = "garment_lemmatizer"
garment_terms = ["\u8eab\u5e45","\u88fe\u5e45","\u30a2\u30fc\u30e0\u30db\u30fc\u30eb","\u672c\u4f53\u88fe\u5e45","\u4e0b\u3052\u672d","\uff1c\u8896\u53e3\uff1e","\u5e73\u30b4\u30e0","16.5cm\u4e21\u7aef\u30ab\u30f3\u6b62\u3081","\u3082\u3063\u3068\u539a\u304f\u5165\u308c\u3066\u4e0b\u3055\u3044\u3002","1, 3\u5c64\u69cb\u9020","4, \u30c0\u30a6\u30f3\u30ad\u30eb\u30c8\u306f\u524d\u8eab\u9803\u306e\u307f\u659c\u308135\u5ea6\u3001\u8896\u3068\u5f8c\u308d\u8eab\u9803\u306f\u6c34\u5e73","22 \u887f  \u5468  \u308a COLLAR OPENING","\u30d1\u30a4\u30d4\u30f3\u30b0\u59cb\u672b","\uff91\uff7c\u304c\u9589\u3058\u305f\u72b6\u614b\u3067"]

[components.sentencizer]
factory = "sentencizer"
overwrite = false
punct_chars = ["!",".","?","\u0589","\u061f","\u06d4","\u0700","\u0701","\u0702","\u07f9","\u0964","\u0965","\u104a","\u104b","\u1362","\u1367","\u1368","\u166e","\u1735","\u1736","\u1803","\u1809","\u1944","\u1945","\u1aa8","\u1aa9","\u1aaa","\u1aab","\u1b5a","\u1b5b","\u1b5e","\u1b5f","\u1c3b","\u1c3c","\u1c7e","\u1c7f","\u203c","\u203d","\u2047","\u2048","\u2049","\u2e2e","\u2e3c","\ua4ff","\ua60e","\ua60f","\ua6f3","\ua6f7","\ua876","\ua877","\ua8ce","\ua8cf","\ua92f","\ua9c8","\ua9c9","\uaa5d","\uaa5e","\uaa5f","\uaaf0","\uaaf1","\uabeb","\ufe52","\ufe56","\ufe57","\uff01","\uff0e","\uff1f","\ud802\ude56","\ud802\ude57","\ud804\udc47","\ud804\udc48","\ud804\udcbe","\ud804\udcbf","\ud804\udcc0","\ud804\udcc1","\ud804\udd41","\ud804\udd42","\ud804\udd43","\ud804\uddc5","\ud804\uddc6","\ud804\uddcd","\ud804\uddde","\ud804\udddf","\ud804\ude38","\ud804\ude39","\ud804\ude3b","\ud804\ude3c","\ud804\udea9","\ud805\udc4b","\ud805\udc4c","\ud805\uddc2","\ud805\uddc3","\ud805\uddc9","\ud805\uddca","\ud805\uddcb","\ud805\uddcc","\ud805\uddcd","\ud805\uddce","\ud805\uddcf","\ud805\uddd0","\ud805\uddd1","\ud805\uddd2","\ud805\uddd3","\ud805\uddd4","\ud805\uddd5","\ud805\uddd6","\ud805\uddd7","\ud805\ude41","\ud805\ude42","\ud805\udf3c","\ud805\udf3d","\ud805\udf3e","\ud806\ude42","\ud806\ude43","\ud806\ude9b","\ud806\ude9c","\ud807\udc41","\ud807\udc42","\ud81a\ude6e","\ud81a\ude6f","\ud81a\udef5","\ud81a\udf37","\ud81a\udf38","\ud81a\udf44","\ud82f\udc9f","\ud836\ude88","\uff61","\u3002","\n"]
scorer = {"@scorers":"spacy.senter_scorer.v1"}

[components.translation_component]
factory = "translation_component"

[components.translation_component.translation_dict]

[corpora]

[corpora.dev]
@readers = "spacy.Corpus.v1"
path = ${paths.dev}
gold_preproc = false
max_length = 0
limit = 0
augmenter = null

[corpora.train]
@readers = "spacy.Corpus.v1"
path = ${paths.train}
gold_preproc = false
max_length = 0
limit = 0
augmenter = null

[training]
seed = ${system.seed}
gpu_allocator = ${system.gpu_allocator}
dropout = 0.1
accumulate_gradient = 1
patience = 1600
max_epochs = 0
max_steps = 20000
eval_frequency = 200
frozen_components = []
annotating_components = []
dev_corpus = "corpora.dev"
train_corpus = "corpora.train"
before_to_disk = null
before_update = null

[training.batcher]
@batchers = "spacy.batch_by_words.v1"
discard_oversize = false
tolerance = 0.2
get_length = null

[training.batcher.size]
@schedules = "compounding.v1"
start = 100
stop = 1000
compound = 1.001
t = 0.0

[training.logger]
@loggers = "spacy.ConsoleLogger.v1"
progress_bar = false

[training.optimizer]
@optimizers = "Adam.v1"
beta1 = 0.9
beta2 = 0.999
L2_is_weight_decay = true
L2 = 0.01
grad_clip = 1.0
use_averages = false
eps = 0.00000001
learn_rate = 0.001

[training.score_weights]
sents_f = 0.5
sents_p = 0.0
sents_r = 0.0
ents_f = 0.5
ents_p = 0.0
ents_r = 0.0
ents_per_type = null

[pretraining]

[initialize]
vectors = ${paths.vectors}
init_tok2vec = ${paths.init_tok2vec}
vocab_data = null
lookups = null
before_init = null
after_init = null

[initialize.components]

[initialize.tokenizer]